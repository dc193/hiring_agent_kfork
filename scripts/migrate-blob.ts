/**
 * Blob Migration Script
 *
 * è¿ç§» Vercel Blob æ•°æ®ä»æ—§é¡¹ç›®åˆ°æ–°é¡¹ç›®
 *
 * ä½¿ç”¨æ–¹æ³•:
 * 1. è®¾ç½®ç¯å¢ƒå˜é‡:
 *    - OLD_BLOB_TOKEN: æ—§é¡¹ç›®çš„ BLOB_READ_WRITE_TOKEN
 *    - NEW_BLOB_TOKEN: æ–°é¡¹ç›®çš„ BLOB_READ_WRITE_TOKEN
 *    - DATABASE_URL: æ•°æ®åº“è¿æ¥
 *
 * 2. è¿è¡Œ: npx tsx scripts/migrate-blob.ts
 */

import { put } from "@vercel/blob";
import { drizzle } from "drizzle-orm/neon-http";
import { neon } from "@neondatabase/serverless";
import { eq } from "drizzle-orm";

// ç®€åŒ–çš„è¡¨å®šä¹‰ï¼ˆåªéœ€è¦è¿ç§»ç”¨åˆ°çš„å­—æ®µï¼‰
import { pgTable, uuid, varchar } from "drizzle-orm/pg-core";

const referenceFiles = pgTable("reference_files", {
  id: uuid("id").primaryKey(),
  fileName: varchar("file_name", { length: 500 }).notNull(),
  blobUrl: varchar("blob_url", { length: 1000 }).notNull(),
});

const attachments = pgTable("attachments", {
  id: uuid("id").primaryKey(),
  fileName: varchar("file_name", { length: 500 }).notNull(),
  blobUrl: varchar("blob_url", { length: 1000 }).notNull(),
});

async function migrateBlob() {
  const OLD_BLOB_TOKEN = process.env.OLD_BLOB_TOKEN;
  const NEW_BLOB_TOKEN = process.env.NEW_BLOB_TOKEN;
  const DATABASE_URL = process.env.DATABASE_URL;

  if (!OLD_BLOB_TOKEN || !NEW_BLOB_TOKEN || !DATABASE_URL) {
    console.error("ç¼ºå°‘ç¯å¢ƒå˜é‡ï¼éœ€è¦è®¾ç½®:");
    console.error("  - OLD_BLOB_TOKEN: æ—§é¡¹ç›®çš„ BLOB_READ_WRITE_TOKEN");
    console.error("  - NEW_BLOB_TOKEN: æ–°é¡¹ç›®çš„ BLOB_READ_WRITE_TOKEN");
    console.error("  - DATABASE_URL: æ•°æ®åº“è¿æ¥");
    process.exit(1);
  }

  const sql = neon(DATABASE_URL);
  const db = drizzle(sql);

  console.log("å¼€å§‹è¿ç§» Blob æ•°æ®...\n");

  // è¿ç§» reference_files
  console.log("=== è¿ç§» reference_files ===");
  const refFiles = await db.select().from(referenceFiles);
  console.log(`æ‰¾åˆ° ${refFiles.length} ä¸ªå‚è€ƒæ–‡ä»¶`);

  for (const file of refFiles) {
    try {
      console.log(`è¿ç§»: ${file.fileName}`);

      // ä¸‹è½½æ—§æ–‡ä»¶
      const response = await fetch(file.blobUrl);
      if (!response.ok) {
        console.error(`  âŒ ä¸‹è½½å¤±è´¥: ${response.status}`);
        continue;
      }
      const blob = await response.blob();

      // ä¸Šä¼ åˆ°æ–° Blobï¼ˆä½¿ç”¨æ–° tokenï¼‰
      const newBlob = await put(file.fileName, blob, {
        access: "public",
        token: NEW_BLOB_TOKEN,
      });

      // æ›´æ–°æ•°æ®åº“
      await db.update(referenceFiles)
        .set({ blobUrl: newBlob.url })
        .where(eq(referenceFiles.id, file.id));

      console.log(`  âœ… å®Œæˆ: ${newBlob.url}`);
    } catch (error) {
      console.error(`  âŒ é”™è¯¯: ${error}`);
    }
  }

  // è¿ç§» attachments
  console.log("\n=== è¿ç§» attachments ===");
  const attachmentFiles = await db.select().from(attachments);
  console.log(`æ‰¾åˆ° ${attachmentFiles.length} ä¸ªé™„ä»¶`);

  for (const file of attachmentFiles) {
    try {
      console.log(`è¿ç§»: ${file.fileName}`);

      // ä¸‹è½½æ—§æ–‡ä»¶
      const response = await fetch(file.blobUrl);
      if (!response.ok) {
        console.error(`  âŒ ä¸‹è½½å¤±è´¥: ${response.status}`);
        continue;
      }
      const blob = await response.blob();

      // ä¸Šä¼ åˆ°æ–° Blob
      const newBlob = await put(file.fileName, blob, {
        access: "public",
        token: NEW_BLOB_TOKEN,
      });

      // æ›´æ–°æ•°æ®åº“
      await db.update(attachments)
        .set({ blobUrl: newBlob.url })
        .where(eq(attachments.id, file.id));

      console.log(`  âœ… å®Œæˆ: ${newBlob.url}`);
    } catch (error) {
      console.error(`  âŒ é”™è¯¯: ${error}`);
    }
  }

  console.log("\nğŸ‰ è¿ç§»å®Œæˆï¼");
}

migrateBlob().catch(console.error);
